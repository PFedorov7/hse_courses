{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Modelling (Day 8): Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification** is a technique where we categorize data into a given number of classes. The main goal of a classification problem is to identify the category/class to which a new data will fall under. Classification is **supervised learning technique**.\n",
    "\n",
    "\n",
    "Terminology:\n",
    "- **Classifier**: an algorithm that maps the input data to a specific category.\n",
    "- **Classification model**: A classification model tries to draw some conclusion from the input values given for training. It will predict the class labels/categories for the new data.\n",
    "- **Feature**: A feature is an individual measurable property of a phenomenon being observed.\n",
    "\n",
    "There are different types of classification: **binary** (2 classes), **multi-class** (>2 classes) and **multi-label** (>1 classes are assigned to an object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "\n",
    "Let us look at data regarding coronary heart disease (CHD) in South Africa.\n",
    "The columns of the dataset:\n",
    "- **sbp**: systolic blood pressure\n",
    "- **tobacco**: cumulative tobacco (kg)\n",
    "- **ldl**: low densiity lipoprotein cholesterol\n",
    "- **adiposity**: severe or morbid overweight\n",
    "- **famhist**: family history of heart disease (Present - 1, Absent - 0)\n",
    "- **typea**: type-A behavior\n",
    "- **obesity**: abnormal or excessive fat accumulation\n",
    "- **alcohol**: current alcohol consumption\n",
    "- **age**: age at onset\n",
    "- **chd**: response, coronary heart disease ($target$ variable)\n",
    "\n",
    "*The goal* is to predict coronary heart desease (CHD) based on other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart = pd.read_csv(r'SAHeart.csv', sep=',', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>age</th>\n",
       "      <th>chd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row.names  sbp  tobacco   ldl  adiposity  famhist  typea  obesity  alcohol  \\\n",
       "0          1  160    12.00  5.73      23.11        1     49    25.30    97.20   \n",
       "1          2  144     0.01  4.41      28.61        0     55    28.87     2.06   \n",
       "2          3  118     0.08  3.48      32.28        1     52    29.14     3.81   \n",
       "3          4  170     7.50  6.41      38.03        1     51    31.99    24.26   \n",
       "4          5  134    13.60  3.50      27.78        1     60    25.99    57.34   \n",
       "\n",
       "   age  chd  \n",
       "0   52    1  \n",
       "1   63    1  \n",
       "2   46    0  \n",
       "3   58    1  \n",
       "4   49    1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us calculate the total number of observations for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    302\n",
       "1    160\n",
       "Name: chd, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart.chd.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![balanced data](https://miro.medium.com/max/450/1*zsyN08VVrgHbAEdvv27Pyw.png \"Balanced And Imbalanced Datasets\")\n",
    "\n",
    "In general, if there are two classes, then *balanced data* would mean 50% points for each of the class. \n",
    "\n",
    "We can observe in our data that **65%** of people have no desease while **35%** of people have no desease. In our case there is a little imbalance in our data which should not cause any significant performance degradation. \n",
    "\n",
    "However, you should remember that **if the class imbalance is high** (e.g. 90% points for one class and 10% for the other), **standard optimization criteria or performance measures may not be as effective and would need modification**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us separates the data frame into a `y` vector of the response and an `X` matrix of explanatory variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = heart.iloc[:,10]\n",
    "X = heart.iloc[:,:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row.names</th>\n",
       "      <th>sbp</th>\n",
       "      <th>tobacco</th>\n",
       "      <th>ldl</th>\n",
       "      <th>adiposity</th>\n",
       "      <th>famhist</th>\n",
       "      <th>typea</th>\n",
       "      <th>obesity</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>12.00</td>\n",
       "      <td>5.73</td>\n",
       "      <td>23.11</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>25.30</td>\n",
       "      <td>97.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.41</td>\n",
       "      <td>28.61</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>28.87</td>\n",
       "      <td>2.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.48</td>\n",
       "      <td>32.28</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>29.14</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>170</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.41</td>\n",
       "      <td>38.03</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>31.99</td>\n",
       "      <td>24.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>134</td>\n",
       "      <td>13.60</td>\n",
       "      <td>3.50</td>\n",
       "      <td>27.78</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>25.99</td>\n",
       "      <td>57.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>459</td>\n",
       "      <td>214</td>\n",
       "      <td>0.40</td>\n",
       "      <td>5.98</td>\n",
       "      <td>31.72</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>28.45</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>460</td>\n",
       "      <td>182</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.41</td>\n",
       "      <td>32.10</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>28.61</td>\n",
       "      <td>18.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>461</td>\n",
       "      <td>108</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.59</td>\n",
       "      <td>15.23</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>20.09</td>\n",
       "      <td>26.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>462</td>\n",
       "      <td>118</td>\n",
       "      <td>5.40</td>\n",
       "      <td>11.61</td>\n",
       "      <td>30.79</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>27.35</td>\n",
       "      <td>23.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>463</td>\n",
       "      <td>132</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.82</td>\n",
       "      <td>33.41</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>14.70</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     row.names  sbp  tobacco    ldl  adiposity  famhist  typea  obesity  \\\n",
       "0            1  160    12.00   5.73      23.11        1     49    25.30   \n",
       "1            2  144     0.01   4.41      28.61        0     55    28.87   \n",
       "2            3  118     0.08   3.48      32.28        1     52    29.14   \n",
       "3            4  170     7.50   6.41      38.03        1     51    31.99   \n",
       "4            5  134    13.60   3.50      27.78        1     60    25.99   \n",
       "..         ...  ...      ...    ...        ...      ...    ...      ...   \n",
       "457        459  214     0.40   5.98      31.72        0     64    28.45   \n",
       "458        460  182     4.20   4.41      32.10        0     52    28.61   \n",
       "459        461  108     3.00   1.59      15.23        0     40    20.09   \n",
       "460        462  118     5.40  11.61      30.79        0     64    27.35   \n",
       "461        463  132     0.00   4.82      33.41        1     62    14.70   \n",
       "\n",
       "     alcohol  \n",
       "0      97.20  \n",
       "1       2.06  \n",
       "2       3.81  \n",
       "3      24.26  \n",
       "4      57.34  \n",
       "..       ...  \n",
       "457     0.00  \n",
       "458    18.72  \n",
       "459    26.64  \n",
       "460    23.97  \n",
       "461     0.00  \n",
       "\n",
       "[462 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the steps involved in building a classification model:\n",
    "\n",
    "- **Initialize** the classifier to be used.\n",
    "- **Train** the classifier: All classifiers in scikit-learn uses a fit(X, y) method to fit the model(training) for the given train data X and train label y.\n",
    "- **Predict** the target: Given an unlabeled observation X, the predict(X) returns the predicted label y.\n",
    "- **Evaluate** the classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Logistic regression\n",
    "Logistic Regression is a type of Generalized Linear Model (GLM) that uses a logistic function to model a binary variable based on any kind of independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr', max_iter=1000).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions (probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25658982, 0.74341018],\n",
       "       [0.7921106 , 0.2078894 ],\n",
       "       [0.65844991, 0.34155009],\n",
       "       [0.212688  , 0.787312  ],\n",
       "       [0.22961532, 0.77038468],\n",
       "       [0.25336953, 0.74663047],\n",
       "       [0.727844  , 0.272156  ],\n",
       "       [0.60409994, 0.39590006],\n",
       "       [0.77534799, 0.22465201],\n",
       "       [0.44453593, 0.55546407],\n",
       "       [0.30529348, 0.69470652],\n",
       "       [0.17381692, 0.82618308],\n",
       "       [0.92545501, 0.07454499],\n",
       "       [0.91446606, 0.08553394],\n",
       "       [0.58586027, 0.41413973],\n",
       "       [0.75969955, 0.24030045],\n",
       "       [0.26896603, 0.73103397],\n",
       "       [0.09778543, 0.90221457],\n",
       "       [0.24919413, 0.75080587],\n",
       "       [0.21707502, 0.78292498],\n",
       "       [0.85909604, 0.14090396],\n",
       "       [0.48109645, 0.51890355],\n",
       "       [0.23160481, 0.76839519],\n",
       "       [0.81477202, 0.18522798],\n",
       "       [0.32665277, 0.67334723],\n",
       "       [0.12230873, 0.87769127],\n",
       "       [0.68363622, 0.31636378],\n",
       "       [0.33142875, 0.66857125],\n",
       "       [0.36379103, 0.63620897],\n",
       "       [0.72181145, 0.27818855],\n",
       "       [0.69303699, 0.30696301],\n",
       "       [0.50396977, 0.49603023],\n",
       "       [0.30404502, 0.69595498],\n",
       "       [0.56327254, 0.43672746],\n",
       "       [0.65231836, 0.34768164],\n",
       "       [0.77935231, 0.22064769],\n",
       "       [0.71464812, 0.28535188],\n",
       "       [0.8341707 , 0.1658293 ],\n",
       "       [0.63324918, 0.36675082],\n",
       "       [0.12417023, 0.87582977],\n",
       "       [0.53458667, 0.46541333],\n",
       "       [0.8951194 , 0.1048806 ],\n",
       "       [0.934879  , 0.065121  ],\n",
       "       [0.69608617, 0.30391383],\n",
       "       [0.99602019, 0.00397981],\n",
       "       [0.69025694, 0.30974306],\n",
       "       [0.15996895, 0.84003105],\n",
       "       [0.60011331, 0.39988669],\n",
       "       [0.92843412, 0.07156588],\n",
       "       [0.76552291, 0.23447709],\n",
       "       [0.64069816, 0.35930184],\n",
       "       [0.7550113 , 0.2449887 ],\n",
       "       [0.5593177 , 0.4406823 ],\n",
       "       [0.57140835, 0.42859165],\n",
       "       [0.6802782 , 0.3197218 ],\n",
       "       [0.48253041, 0.51746959],\n",
       "       [0.92481604, 0.07518396],\n",
       "       [0.75052948, 0.24947052],\n",
       "       [0.90081888, 0.09918112],\n",
       "       [0.6695993 , 0.3304007 ],\n",
       "       [0.85042099, 0.14957901],\n",
       "       [0.4338954 , 0.5661046 ],\n",
       "       [0.2453733 , 0.7546267 ],\n",
       "       [0.88326099, 0.11673901],\n",
       "       [0.92661099, 0.07338901],\n",
       "       [0.38893133, 0.61106867],\n",
       "       [0.75015944, 0.24984056],\n",
       "       [0.96511139, 0.03488861],\n",
       "       [0.49957404, 0.50042596],\n",
       "       [0.81910877, 0.18089123],\n",
       "       [0.89160226, 0.10839774],\n",
       "       [0.79959578, 0.20040422],\n",
       "       [0.73879253, 0.26120747],\n",
       "       [0.63746236, 0.36253764],\n",
       "       [0.74215005, 0.25784995],\n",
       "       [0.84393747, 0.15606253],\n",
       "       [0.79519254, 0.20480746],\n",
       "       [0.39241492, 0.60758508],\n",
       "       [0.53959348, 0.46040652],\n",
       "       [0.65713063, 0.34286937],\n",
       "       [0.44088423, 0.55911577],\n",
       "       [0.81836265, 0.18163735],\n",
       "       [0.15846247, 0.84153753],\n",
       "       [0.3597587 , 0.6402413 ],\n",
       "       [0.7166063 , 0.2833937 ],\n",
       "       [0.83589898, 0.16410102],\n",
       "       [0.47161233, 0.52838767],\n",
       "       [0.69070811, 0.30929189],\n",
       "       [0.59237798, 0.40762202],\n",
       "       [0.88309213, 0.11690787],\n",
       "       [0.94053772, 0.05946228],\n",
       "       [0.6386565 , 0.3613435 ],\n",
       "       [0.88065788, 0.11934212],\n",
       "       [0.85226789, 0.14773211],\n",
       "       [0.58810152, 0.41189848],\n",
       "       [0.66413421, 0.33586579],\n",
       "       [0.67118484, 0.32881516],\n",
       "       [0.63926879, 0.36073121],\n",
       "       [0.18379547, 0.81620453],\n",
       "       [0.55241037, 0.44758963],\n",
       "       [0.2503452 , 0.7496548 ],\n",
       "       [0.76701552, 0.23298448],\n",
       "       [0.76061652, 0.23938348],\n",
       "       [0.91894531, 0.08105469],\n",
       "       [0.79405928, 0.20594072],\n",
       "       [0.64919851, 0.35080149],\n",
       "       [0.71649294, 0.28350706],\n",
       "       [0.46769816, 0.53230184],\n",
       "       [0.74962428, 0.25037572],\n",
       "       [0.89919935, 0.10080065],\n",
       "       [0.73474035, 0.26525965],\n",
       "       [0.12791996, 0.87208004],\n",
       "       [0.85087192, 0.14912808],\n",
       "       [0.30122781, 0.69877219],\n",
       "       [0.25584004, 0.74415996],\n",
       "       [0.4133844 , 0.5866156 ],\n",
       "       [0.6828854 , 0.3171146 ],\n",
       "       [0.84423236, 0.15576764],\n",
       "       [0.35061392, 0.64938608],\n",
       "       [0.8084229 , 0.1915771 ],\n",
       "       [0.66430656, 0.33569344],\n",
       "       [0.80672886, 0.19327114],\n",
       "       [0.78088692, 0.21911308],\n",
       "       [0.68217536, 0.31782464],\n",
       "       [0.63289927, 0.36710073],\n",
       "       [0.14275538, 0.85724462],\n",
       "       [0.79995933, 0.20004067],\n",
       "       [0.75627455, 0.24372545],\n",
       "       [0.74025923, 0.25974077],\n",
       "       [0.24230523, 0.75769477],\n",
       "       [0.30644282, 0.69355718],\n",
       "       [0.86151091, 0.13848909],\n",
       "       [0.88876247, 0.11123753],\n",
       "       [0.61314807, 0.38685193],\n",
       "       [0.6412163 , 0.3587837 ],\n",
       "       [0.33383973, 0.66616027],\n",
       "       [0.87333239, 0.12666761],\n",
       "       [0.6758696 , 0.3241304 ],\n",
       "       [0.90973505, 0.09026495],\n",
       "       [0.63905241, 0.36094759],\n",
       "       [0.3554183 , 0.6445817 ],\n",
       "       [0.59846457, 0.40153543],\n",
       "       [0.82567083, 0.17432917],\n",
       "       [0.59697304, 0.40302696],\n",
       "       [0.77753166, 0.22246834],\n",
       "       [0.82224347, 0.17775653],\n",
       "       [0.83525309, 0.16474691],\n",
       "       [0.50139611, 0.49860389],\n",
       "       [0.80754651, 0.19245349],\n",
       "       [0.49330661, 0.50669339],\n",
       "       [0.59323556, 0.40676444],\n",
       "       [0.76682387, 0.23317613],\n",
       "       [0.86672051, 0.13327949],\n",
       "       [0.94743812, 0.05256188],\n",
       "       [0.55496564, 0.44503436],\n",
       "       [0.38985831, 0.61014169],\n",
       "       [0.9304405 , 0.0695595 ],\n",
       "       [0.44261361, 0.55738639],\n",
       "       [0.91166119, 0.08833881],\n",
       "       [0.56156629, 0.43843371],\n",
       "       [0.75576761, 0.24423239],\n",
       "       [0.09061767, 0.90938233],\n",
       "       [0.91675878, 0.08324122],\n",
       "       [0.7134998 , 0.2865002 ],\n",
       "       [0.92770722, 0.07229278],\n",
       "       [0.55904814, 0.44095186],\n",
       "       [0.67511754, 0.32488246],\n",
       "       [0.30946877, 0.69053123],\n",
       "       [0.77759366, 0.22240634],\n",
       "       [0.38460355, 0.61539645],\n",
       "       [0.17302806, 0.82697194],\n",
       "       [0.88764389, 0.11235611],\n",
       "       [0.75592733, 0.24407267],\n",
       "       [0.82661537, 0.17338463],\n",
       "       [0.56504657, 0.43495343],\n",
       "       [0.58594132, 0.41405868],\n",
       "       [0.79493214, 0.20506786],\n",
       "       [0.9126873 , 0.0873127 ],\n",
       "       [0.6262228 , 0.3737772 ],\n",
       "       [0.55079828, 0.44920172],\n",
       "       [0.7929188 , 0.2070812 ],\n",
       "       [0.66664459, 0.33335541],\n",
       "       [0.30641695, 0.69358305],\n",
       "       [0.59533251, 0.40466749],\n",
       "       [0.47107133, 0.52892867],\n",
       "       [0.71320869, 0.28679131],\n",
       "       [0.19796844, 0.80203156],\n",
       "       [0.760447  , 0.239553  ],\n",
       "       [0.32026965, 0.67973035],\n",
       "       [0.51325984, 0.48674016],\n",
       "       [0.83506381, 0.16493619],\n",
       "       [0.55104105, 0.44895895],\n",
       "       [0.80464878, 0.19535122],\n",
       "       [0.81698735, 0.18301265],\n",
       "       [0.9387112 , 0.0612888 ],\n",
       "       [0.82594368, 0.17405632],\n",
       "       [0.90397747, 0.09602253],\n",
       "       [0.74308683, 0.25691317],\n",
       "       [0.46920363, 0.53079637],\n",
       "       [0.82330177, 0.17669823],\n",
       "       [0.90722673, 0.09277327],\n",
       "       [0.61188031, 0.38811969],\n",
       "       [0.81168738, 0.18831262],\n",
       "       [0.83324177, 0.16675823],\n",
       "       [0.73189498, 0.26810502],\n",
       "       [0.805766  , 0.194234  ],\n",
       "       [0.50131275, 0.49868725],\n",
       "       [0.46594548, 0.53405452],\n",
       "       [0.55269923, 0.44730077],\n",
       "       [0.48328893, 0.51671107],\n",
       "       [0.7573268 , 0.2426732 ],\n",
       "       [0.46771479, 0.53228521],\n",
       "       [0.82364433, 0.17635567],\n",
       "       [0.91465889, 0.08534111],\n",
       "       [0.85762321, 0.14237679],\n",
       "       [0.36734799, 0.63265201],\n",
       "       [0.79002172, 0.20997828],\n",
       "       [0.92689419, 0.07310581],\n",
       "       [0.97083709, 0.02916291],\n",
       "       [0.32726453, 0.67273547],\n",
       "       [0.89715405, 0.10284595],\n",
       "       [0.68926335, 0.31073665],\n",
       "       [0.57836216, 0.42163784],\n",
       "       [0.29992751, 0.70007249],\n",
       "       [0.74950561, 0.25049439],\n",
       "       [0.69233615, 0.30766385],\n",
       "       [0.40071431, 0.59928569],\n",
       "       [0.663274  , 0.336726  ],\n",
       "       [0.53426846, 0.46573154],\n",
       "       [0.28838455, 0.71161545],\n",
       "       [0.71141675, 0.28858325],\n",
       "       [0.38682333, 0.61317667],\n",
       "       [0.75144715, 0.24855285],\n",
       "       [0.8492037 , 0.1507963 ],\n",
       "       [0.81763139, 0.18236861],\n",
       "       [0.46560484, 0.53439516],\n",
       "       [0.71623065, 0.28376935],\n",
       "       [0.46018409, 0.53981591],\n",
       "       [0.8411717 , 0.1588283 ],\n",
       "       [0.93370361, 0.06629639],\n",
       "       [0.63328082, 0.36671918],\n",
       "       [0.60660844, 0.39339156],\n",
       "       [0.70406532, 0.29593468],\n",
       "       [0.58992682, 0.41007318],\n",
       "       [0.37923248, 0.62076752],\n",
       "       [0.87528407, 0.12471593],\n",
       "       [0.57535152, 0.42464848],\n",
       "       [0.51033425, 0.48966575],\n",
       "       [0.73834929, 0.26165071],\n",
       "       [0.38604701, 0.61395299],\n",
       "       [0.56937107, 0.43062893],\n",
       "       [0.88497341, 0.11502659],\n",
       "       [0.66001176, 0.33998824],\n",
       "       [0.23180392, 0.76819608],\n",
       "       [0.44876086, 0.55123914],\n",
       "       [0.14349568, 0.85650432],\n",
       "       [0.59216955, 0.40783045],\n",
       "       [0.62308176, 0.37691824],\n",
       "       [0.43087946, 0.56912054],\n",
       "       [0.59048643, 0.40951357],\n",
       "       [0.92562536, 0.07437464],\n",
       "       [0.74640141, 0.25359859],\n",
       "       [0.77490195, 0.22509805],\n",
       "       [0.51856642, 0.48143358],\n",
       "       [0.3557472 , 0.6442528 ],\n",
       "       [0.92656521, 0.07343479],\n",
       "       [0.90958725, 0.09041275],\n",
       "       [0.47813038, 0.52186962],\n",
       "       [0.73117111, 0.26882889],\n",
       "       [0.25070383, 0.74929617],\n",
       "       [0.61333862, 0.38666138],\n",
       "       [0.81683402, 0.18316598],\n",
       "       [0.79720457, 0.20279543],\n",
       "       [0.64867298, 0.35132702],\n",
       "       [0.93403551, 0.06596449],\n",
       "       [0.37350216, 0.62649784],\n",
       "       [0.40657219, 0.59342781],\n",
       "       [0.56499715, 0.43500285],\n",
       "       [0.94270071, 0.05729929],\n",
       "       [0.93535928, 0.06464072],\n",
       "       [0.78232353, 0.21767647],\n",
       "       [0.77868002, 0.22131998],\n",
       "       [0.49146391, 0.50853609],\n",
       "       [0.94550567, 0.05449433],\n",
       "       [0.13608949, 0.86391051],\n",
       "       [0.88003529, 0.11996471],\n",
       "       [0.96341023, 0.03658977],\n",
       "       [0.93384643, 0.06615357],\n",
       "       [0.92382668, 0.07617332],\n",
       "       [0.86828589, 0.13171411],\n",
       "       [0.95679812, 0.04320188],\n",
       "       [0.87797476, 0.12202524],\n",
       "       [0.89495851, 0.10504149],\n",
       "       [0.2709649 , 0.7290351 ],\n",
       "       [0.82372453, 0.17627547],\n",
       "       [0.87214337, 0.12785663],\n",
       "       [0.85737194, 0.14262806],\n",
       "       [0.8996078 , 0.1003922 ],\n",
       "       [0.64210457, 0.35789543],\n",
       "       [0.60701147, 0.39298853],\n",
       "       [0.64581139, 0.35418861],\n",
       "       [0.77051224, 0.22948776],\n",
       "       [0.8755454 , 0.1244546 ],\n",
       "       [0.45181386, 0.54818614],\n",
       "       [0.9487893 , 0.0512107 ],\n",
       "       [0.81837406, 0.18162594],\n",
       "       [0.26331437, 0.73668563],\n",
       "       [0.8133133 , 0.1866867 ],\n",
       "       [0.86921676, 0.13078324],\n",
       "       [0.74983161, 0.25016839],\n",
       "       [0.53534108, 0.46465892],\n",
       "       [0.76364682, 0.23635318],\n",
       "       [0.73152956, 0.26847044],\n",
       "       [0.87648662, 0.12351338],\n",
       "       [0.59112318, 0.40887682],\n",
       "       [0.8626383 , 0.1373617 ],\n",
       "       [0.72720653, 0.27279347],\n",
       "       [0.93597248, 0.06402752],\n",
       "       [0.26659117, 0.73340883],\n",
       "       [0.67024039, 0.32975961],\n",
       "       [0.55581844, 0.44418156],\n",
       "       [0.68830392, 0.31169608],\n",
       "       [0.75689271, 0.24310729],\n",
       "       [0.43097878, 0.56902122],\n",
       "       [0.78567761, 0.21432239],\n",
       "       [0.83936414, 0.16063586],\n",
       "       [0.7434322 , 0.2565678 ],\n",
       "       [0.8904129 , 0.1095871 ],\n",
       "       [0.90181292, 0.09818708],\n",
       "       [0.8962784 , 0.1037216 ],\n",
       "       [0.95172637, 0.04827363],\n",
       "       [0.6550079 , 0.3449921 ],\n",
       "       [0.23374387, 0.76625613],\n",
       "       [0.44718821, 0.55281179],\n",
       "       [0.65528508, 0.34471492],\n",
       "       [0.3315883 , 0.6684117 ],\n",
       "       [0.83285535, 0.16714465],\n",
       "       [0.63998192, 0.36001808],\n",
       "       [0.76659991, 0.23340009],\n",
       "       [0.90552946, 0.09447054],\n",
       "       [0.76516072, 0.23483928],\n",
       "       [0.44311505, 0.55688495],\n",
       "       [0.36462125, 0.63537875],\n",
       "       [0.96275249, 0.03724751],\n",
       "       [0.80186948, 0.19813052],\n",
       "       [0.28827281, 0.71172719],\n",
       "       [0.61966587, 0.38033413],\n",
       "       [0.85755912, 0.14244088],\n",
       "       [0.65954489, 0.34045511],\n",
       "       [0.82646658, 0.17353342],\n",
       "       [0.4115815 , 0.5884185 ],\n",
       "       [0.72831164, 0.27168836],\n",
       "       [0.33466997, 0.66533003],\n",
       "       [0.39977679, 0.60022321],\n",
       "       [0.49595778, 0.50404222],\n",
       "       [0.69471665, 0.30528335],\n",
       "       [0.92703468, 0.07296532],\n",
       "       [0.68514756, 0.31485244],\n",
       "       [0.73810717, 0.26189283],\n",
       "       [0.85791695, 0.14208305],\n",
       "       [0.2923811 , 0.7076189 ],\n",
       "       [0.93147218, 0.06852782],\n",
       "       [0.63078923, 0.36921077],\n",
       "       [0.55820673, 0.44179327],\n",
       "       [0.50434907, 0.49565093],\n",
       "       [0.92247724, 0.07752276],\n",
       "       [0.86258342, 0.13741658],\n",
       "       [0.88314573, 0.11685427],\n",
       "       [0.61148857, 0.38851143],\n",
       "       [0.7613467 , 0.2386533 ],\n",
       "       [0.24324219, 0.75675781],\n",
       "       [0.37184676, 0.62815324],\n",
       "       [0.77476093, 0.22523907],\n",
       "       [0.44340544, 0.55659456],\n",
       "       [0.74688438, 0.25311562],\n",
       "       [0.9394072 , 0.0605928 ],\n",
       "       [0.83843697, 0.16156303],\n",
       "       [0.64234415, 0.35765585],\n",
       "       [0.87360268, 0.12639732],\n",
       "       [0.6388945 , 0.3611055 ],\n",
       "       [0.89325506, 0.10674494],\n",
       "       [0.59996662, 0.40003338],\n",
       "       [0.27343349, 0.72656651],\n",
       "       [0.74704576, 0.25295424],\n",
       "       [0.30752245, 0.69247755],\n",
       "       [0.33477341, 0.66522659],\n",
       "       [0.50464299, 0.49535701],\n",
       "       [0.42796706, 0.57203294],\n",
       "       [0.86593956, 0.13406044],\n",
       "       [0.50752744, 0.49247256],\n",
       "       [0.63685647, 0.36314353],\n",
       "       [0.4455418 , 0.5544582 ],\n",
       "       [0.80317318, 0.19682682],\n",
       "       [0.71421375, 0.28578625],\n",
       "       [0.74099813, 0.25900187],\n",
       "       [0.92002113, 0.07997887],\n",
       "       [0.44555602, 0.55444398],\n",
       "       [0.49250877, 0.50749123],\n",
       "       [0.51307773, 0.48692227],\n",
       "       [0.86614988, 0.13385012],\n",
       "       [0.7450332 , 0.2549668 ],\n",
       "       [0.822782  , 0.177218  ],\n",
       "       [0.42478756, 0.57521244],\n",
       "       [0.40926793, 0.59073207],\n",
       "       [0.68976807, 0.31023193],\n",
       "       [0.62566844, 0.37433156],\n",
       "       [0.05862481, 0.94137519],\n",
       "       [0.08042066, 0.91957934],\n",
       "       [0.86543626, 0.13456374],\n",
       "       [0.9183573 , 0.0816427 ],\n",
       "       [0.16717676, 0.83282324],\n",
       "       [0.8242945 , 0.1757055 ],\n",
       "       [0.18524062, 0.81475938],\n",
       "       [0.50334901, 0.49665099],\n",
       "       [0.43941087, 0.56058913],\n",
       "       [0.73603668, 0.26396332],\n",
       "       [0.50493678, 0.49506322],\n",
       "       [0.7169438 , 0.2830562 ],\n",
       "       [0.64838501, 0.35161499],\n",
       "       [0.85520424, 0.14479576],\n",
       "       [0.84721118, 0.15278882],\n",
       "       [0.86348171, 0.13651829],\n",
       "       [0.30248861, 0.69751139],\n",
       "       [0.48040192, 0.51959808],\n",
       "       [0.88102718, 0.11897282],\n",
       "       [0.93584609, 0.06415391],\n",
       "       [0.58615135, 0.41384865],\n",
       "       [0.85442934, 0.14557066],\n",
       "       [0.62677528, 0.37322472],\n",
       "       [0.91540181, 0.08459819],\n",
       "       [0.86546826, 0.13453174],\n",
       "       [0.90544762, 0.09455238],\n",
       "       [0.91708262, 0.08291738],\n",
       "       [0.95555413, 0.04444587],\n",
       "       [0.77616145, 0.22383855],\n",
       "       [0.92167281, 0.07832719],\n",
       "       [0.82990706, 0.17009294],\n",
       "       [0.88259604, 0.11740396],\n",
       "       [0.92395596, 0.07604404],\n",
       "       [0.85985457, 0.14014543],\n",
       "       [0.85599118, 0.14400882],\n",
       "       [0.8613472 , 0.1386528 ],\n",
       "       [0.51045145, 0.48954855],\n",
       "       [0.8304291 , 0.1695709 ],\n",
       "       [0.87616265, 0.12383735],\n",
       "       [0.78381187, 0.21618813],\n",
       "       [0.91809751, 0.08190249],\n",
       "       [0.85337392, 0.14662608],\n",
       "       [0.83009886, 0.16990114],\n",
       "       [0.60135564, 0.39864436],\n",
       "       [0.90775249, 0.09224751],\n",
       "       [0.92782123, 0.07217877],\n",
       "       [0.46556941, 0.53443059],\n",
       "       [0.63299954, 0.36700046],\n",
       "       [0.81762828, 0.18237172],\n",
       "       [0.87456361, 0.12543639],\n",
       "       [0.49728208, 0.50271792],\n",
       "       [0.53074025, 0.46925975],\n",
       "       [0.68325357, 0.31674643],\n",
       "       [0.95065705, 0.04934295],\n",
       "       [0.4515899 , 0.5484101 ],\n",
       "       [0.21456133, 0.78543867]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the score (average accuracy) of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7359307359307359"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.score(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[262,  40],\n",
       "       [ 82,  78]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, LR.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the F-score of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5611510791366906"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, LR.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. K-Nearest Neighbours\n",
    "According to K-Nearest Neighbours algorithm, classification is computed from a simple majority vote of the k nearest neighbours of each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7359307359307359\n",
      "F-1 score is 0.5234375\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is\", knn.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, knn.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decision Tree\n",
    "Given a data of attributes together with its classes, a decision tree produces a sequence of rules that can be used to classify the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, min_samples_leaf=5, random_state=101)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth = 5, random_state = 101, min_samples_leaf = 5)\n",
    "dtree.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7835497835497836\n",
      "F-1 score is 0.6551724137931033\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is\", dtree.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, dtree.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Random Forest\n",
    "Random Forests are an ensemble learning method that fit multiple Decision Trees on subsets of the data and average the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=2, random_state=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "RF.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7207792207792207\n",
      "F-1 score is 0.3827751196172249\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is\", RF.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, RF.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Support Vector Machines\n",
    "Support Vector Machines (SVMs) are a type of classification algorithm that are more flexible - they can do linear classification, but can use other non-linear basis functions. The following example uses a linear classifier to fit a hyperplane that separates the data into two classes. To apply SVM, you may call `LinearSVC` or `SVC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = sk.svm.SVC(kernel='linear')\n",
    "SVM.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy and F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.3220338983050847\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is\", SVM.score(X,y))\n",
    "# print(\"F-1 score is\", f1_score(y, SVM.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Neural Networks\n",
    "Neural Networks are a machine learning algorithm that involves fitting many hidden layers used to represent neurons that are connected with synaptic activation functions. These essentially use a very simplified model of the brain to model and predict data.\n",
    "\n",
    "One can use `sklearn` library for neural networks, however libraries such as `Tensorflow` and `Keras` are more suited to fitting and customizing neural networks. We will try these libraries next week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(5, 2), random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "NN.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy and F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.3220338983050847\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-16b9ea34f4a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F-1 score is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1045\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                        zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1176\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1434\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1263\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m   1264\u001b[0m                              \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m                              % (y_type, average_options))\n\u001b[0m\u001b[1;32m   1266\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is\", NN.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, NN.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Naive Bayes\n",
    "\n",
    "Naive Bayes algorithm based on Bayes’ theorem with the assumption of independence between every pair of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 3, 3, 3, 3, 4, 1, 1, 3, 1, 3, 3, 3, 1, 1, 1, 3, 1, 3, 1, 4,\n",
       "       4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy and F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.847457627118644\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-985a55cc4169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F-1 score is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1045\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                        zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1176\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1434\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1263\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m   1264\u001b[0m                              \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m                              % (y_type, average_options))\n\u001b[0m\u001b[1;32m   1266\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is\", nb.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, nb.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other classifiers\n",
    "\n",
    "**8. Stochastic Gradient Descent**\n",
    "\n",
    "Stochastic gradient descent is a simple and very efficient approach to fit linear models. It is particularly useful when the number of samples is very large. It supports different loss functions and penalties for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(loss='modified_huber', random_state=101)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='modified_huber', shuffle=True, random_state=101)\n",
    "sgd.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy and F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.3728813559322034\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-0b9b4e5e723e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F-1 score is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1045\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                        zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1176\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1434\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1263\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m   1264\u001b[0m                              \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m                              % (y_type, average_options))\n\u001b[0m\u001b[1;32m   1266\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is\", sgd.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, sgd.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. XGBoost**\n",
    "\n",
    "XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It is an implementation of the Gradient Boosted Decision Trees algorithm. **The idea** is that it go through cycles that repeatedly builds new models and combines them into an ensemble model. XGBoost models dominate many Kaggle competitions.\n",
    "\n",
    "More information is available [here](https://www.kaggle.com/dansbecker/xgboost)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy and F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 1.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-4d8f45c4fb4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F-1 score is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1045\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                        zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1176\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1434\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1263\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m   1264\u001b[0m                              \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m                              % (y_type, average_options))\n\u001b[0m\u001b[1;32m   1266\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is\", xgb.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, xgb.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Linear Discriminant Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-57-24500201d9d9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-57-24500201d9d9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Compute the accuracy and F-1 score\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Compute the accuracy and F-1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 1.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-4d8f45c4fb4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"F-1 score is\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1045\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                        zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1173\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1176\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1434\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1263\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m   1264\u001b[0m                              \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m                              % (y_type, average_options))\n\u001b[0m\u001b[1;32m   1266\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is\", xgb.score(X,y))\n",
    "print(\"F-1 score is\", f1_score(y, xgb.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-17df60d9bc63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m results = [[precision_score(y, LR.predict(X)), recall_score(y, LR.predict(X)), LR.score(X,y), f1_score(y, LR.predict(X))],\n\u001b[0m\u001b[1;32m      2\u001b[0m            \u001b[0;34m[\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m            \u001b[0;34m[\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m            \u001b[0;34m[\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m            \u001b[0;34m[\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSVM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1621\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1624\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1434\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1263\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m   1264\u001b[0m                              \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m                              % (y_type, average_options))\n\u001b[0m\u001b[1;32m   1266\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "results = [[precision_score(y, LR.predict(X)), recall_score(y, LR.predict(X)), LR.score(X,y), f1_score(y, LR.predict(X))],\n",
    "           [precision_score(y, knn.predict(X)), recall_score(y, knn.predict(X)), knn.score(X,y), f1_score(y, knn.predict(X))],\n",
    "           [precision_score(y, dtree.predict(X)), recall_score(y, dtree.predict(X)), dtree.score(X,y), f1_score(y, dtree.predict(X))],\n",
    "           [precision_score(y, RF.predict(X)), recall_score(y, RF.predict(X)), RF.score(X,y), f1_score(y, RF.predict(X))],\n",
    "           [precision_score(y, SVM.predict(X)), recall_score(y, SVM.predict(X)), SVM.score(X,y), f1_score(y, SVM.predict(X))],\n",
    "           [precision_score(y, NN.predict(X)), recall_score(y, NN.predict(X)), NN.score(X,y), f1_score(y, NN.predict(X))],\n",
    "           [precision_score(y, nb.predict(X)), recall_score(y, nb.predict(X)), nb.score(X,y), f1_score(y, nb.predict(X))],\n",
    "           [precision_score(y, sgd.predict(X)), recall_score(y, sgd.predict(X)), sgd.score(X,y), f1_score(y, sgd.predict(X))],\n",
    "           [precision_score(y, xgb.predict(X)), recall_score(y, xgb.predict(X)), xgb.score(X,y), f1_score(y, xgb.predict(X))],\n",
    "           [precision_score(y, lda.predict(X)), recall_score(y, lda.predict(X)), lda.score(X,y), f1_score(y, lda.predict(X))]]\n",
    "\n",
    "df = pd.DataFrame(data=results, \n",
    "                  index=[\"Logistic Regression\", \"K-Nearest Neighbours\", \"Decision Tree\", \"Random Forest\",\n",
    "                        \"SVM\", \"Neural Networks\", \"Naive Bayes\", \"SGD\", \"XGBoost\", \"Linear Discriminant Analysis\"], \n",
    "                  columns=[\"Precision\", \"Recall\", \"Accuracy\", \"F1-score\"])\n",
    "df['label'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-00cf07b74dcd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_point(x, y, val, ax):\n",
    "    a = pd.concat({'x': x, 'y': y, 'val': val}, axis=1)\n",
    "    for i, point in a.iterrows():\n",
    "        ax.text(point['x'], point['y'], str(point['val']))\n",
    "\n",
    "        \n",
    "def drawScatter(df, col1, col2, label=\"label\"):\n",
    "    plt.style.use(\"fivethirtyeight\")\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax = fig.gca()\n",
    "    label_point(df[col1], df[col2], df.label, ax)\n",
    "    df.plot.scatter(x=col1, y=col2, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-eedebf6a6fbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrawScatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Recall'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "drawScatter(df, 'Precision', 'Recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-0f95821b20d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrawScatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F1-score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "drawScatter(df, 'Accuracy', 'F1-score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class Classification\n",
    "Let us consider the fruits dataset (fruit_data_with_colors.txt) which contains a few dozen oranges, lemons and apples of different varieties and their measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit_label</th>\n",
       "      <th>fruit_name</th>\n",
       "      <th>fruit_subtype</th>\n",
       "      <th>mass</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>color_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>192</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>180</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>176</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>86</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>84</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fruit_label fruit_name fruit_subtype  mass  width  height  color_score\n",
       "0            1      apple  granny_smith   192    8.4     7.3         0.55\n",
       "1            1      apple  granny_smith   180    8.0     6.8         0.59\n",
       "2            1      apple  granny_smith   176    7.4     7.2         0.60\n",
       "3            2   mandarin      mandarin    86    6.2     4.7         0.80\n",
       "4            2   mandarin      mandarin    84    6.0     4.6         0.79"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits = pd.read_table('fruit_data_with_colors.txt')\n",
    "fruits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 59 pieces of fruits and 7 features in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59, 7)\n"
     ]
    }
   ],
   "source": [
    "print(fruits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fruit_name\n",
      "apple       19\n",
      "lemon       16\n",
      "mandarin     5\n",
      "orange      19\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(fruits.groupby('fruit_name').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(fruits['fruit_name'],label=\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our data is more or less balanced, thus, no additional techniques are required.\n",
    "\n",
    "Let us draw some histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To output multiple subplots, the figure containing the passed axes is being cleared\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1, 'List of histograms')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "ax = fig.gca()\n",
    "fruits.hist(ax = ax, bins=30)\n",
    "plt.suptitle('List of histograms', x=0.5, y=1, ha='center', fontsize='xx-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some pairs of attributes are correlated (mass and width). This suggests a high correlation and a predictable relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit_label</th>\n",
       "      <th>mass</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>color_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.542373</td>\n",
       "      <td>163.118644</td>\n",
       "      <td>7.105085</td>\n",
       "      <td>7.693220</td>\n",
       "      <td>0.762881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.208048</td>\n",
       "      <td>55.018832</td>\n",
       "      <td>0.816938</td>\n",
       "      <td>1.361017</td>\n",
       "      <td>0.076857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>362.000000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fruit_label        mass      width     height  color_score\n",
       "count    59.000000   59.000000  59.000000  59.000000    59.000000\n",
       "mean      2.542373  163.118644   7.105085   7.693220     0.762881\n",
       "std       1.208048   55.018832   0.816938   1.361017     0.076857\n",
       "min       1.000000   76.000000   5.800000   4.000000     0.550000\n",
       "25%       1.000000  140.000000   6.600000   7.200000     0.720000\n",
       "50%       3.000000  158.000000   7.200000   7.600000     0.750000\n",
       "75%       4.000000  177.000000   7.500000   8.200000     0.810000\n",
       "max       4.000000  362.000000   9.600000  10.500000     0.930000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the numerical values do not have the same scale. We will need to apply scaling to the test set that we computed for the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training and Test Sets and Apply Scaling\n",
    "\n",
    "The split of the dataset is performed using the `train_test_split` methods which is a part of `sklearn` package. By default, the data is divided into 2 parts: training set (75%) and test set (25%). However, it is also possible to set the size of the dataset (e.g., input parameter `test_size=0.3` which corresponds to 30% splitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fruits.iloc[:,0]\n",
    "X = fruits.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let us rescale our data.\n",
    "`MinMaxScaler` estimator scales and translates each feature individually such that it is in the given range on the training set, e.g. between zero and one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Models\n",
    "\n",
    "We use the training set to learn the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. LR\n",
    "LR = LogisticRegression(random_state=0, solver='lbfgs', multi_class='ovr', max_iter=1000)\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "#2. knn\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#3. Desicion tree\n",
    "dtree = DecisionTreeClassifier(max_depth = 5, random_state = 101, min_samples_leaf = 5)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "#4. Random Forest\n",
    "RF = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "RF.fit(X_train, y_train)\n",
    "\n",
    "#5. SVM\n",
    "SVM = sk.svm.SVC(kernel='linear')\n",
    "SVM.fit(X_train, y_train)\n",
    "\n",
    "#7. Naive Bayes\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "#8. SGD\n",
    "sgd = SGDClassifier(loss='modified_huber', shuffle=True, random_state=101)\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "#9. XGBoost\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "#10. LDA\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LR classifier 0.4666666666666667\n",
      "Accuracy of KNN classifier 1.0\n",
      "Accuracy of Desicion tree classifier 0.7333333333333333\n",
      "Accuracy of Random Forest classifier 0.8\n",
      "Accuracy of SVM classifier 0.5333333333333333\n",
      "Accuracy of Naive Bayes classifier 0.6666666666666666\n",
      "Accuracy of SGD classifier 0.5333333333333333\n",
      "Accuracy of XGBoost classifier 0.8\n",
      "Accuracy of LDA classifier 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of LR classifier', LR.score(X_test,y_test))\n",
    "print('Accuracy of KNN classifier', knn.score(X_test,y_test))\n",
    "print('Accuracy of Desicion tree classifier', dtree.score(X_test,y_test))\n",
    "print('Accuracy of Random Forest classifier', RF.score(X_test,y_test))\n",
    "print('Accuracy of SVM classifier', SVM.score(X_test,y_test))\n",
    "print('Accuracy of Naive Bayes classifier', nb.score(X_test,y_test))\n",
    "print('Accuracy of SGD classifier', sgd.score(X_test,y_test))\n",
    "print('Accuracy of XGBoost classifier', xgb.score(X_test,y_test))\n",
    "print('Accuracy of LDA classifier', lda.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The KNN algorithm was the most accurate model that we tried. The confusion matrix provides an indication of no error made on the test set. However, the test set was very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 4 3 1 1 3 4 3 1 2 1 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "pred = knn.predict(X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also construct the confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 8 0]\n",
      " [0 0 0 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        15\n",
      "   macro avg       1.00      1.00      1.00        15\n",
      "weighted avg       1.00      1.00      1.00        15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, pred))\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional: Define the optimal number of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x7fc9206425d0>,\n",
       "  <matplotlib.axis.XTick at 0x7fc91ffbf690>,\n",
       "  <matplotlib.axis.XTick at 0x7fc92048e150>,\n",
       "  <matplotlib.axis.XTick at 0x7fc92066e7d0>,\n",
       "  <matplotlib.axis.XTick at 0x7fc92066ed90>],\n",
       " <a list of 5 Text xticklabel objects>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_range = range(1, 20)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "plt.figure()\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('accuracy')\n",
    "plt.scatter(k_range, scores)\n",
    "plt.xticks([0,5,10,15,20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity to the size of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-ca2276c0ffb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bo'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training set proportion (%)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = [0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2]\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for s in t:\n",
    "    scores = []\n",
    "    for i in range(1,1000):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1-s)\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        knn.fit(X_train, y_train)\n",
    "        scores.append(knn.score(X_test, y_test))\n",
    "    plt.plot(s, np.mean(scores), 'bo')\n",
    "\n",
    "plt.xlabel('Training set proportion (%)')\n",
    "plt.ylabel('accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional: Plot the Decision Boundary of the k-NN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "X = fruits[['mass', 'width', 'height', 'color_score']]\n",
    "y = fruits['fruit_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "\n",
    "def plot_fruit_knn(X, y, n_neighbors, weights):\n",
    "    X_mat = X[['height', 'width']].values\n",
    "    y_mat = y.values\n",
    "# Create color maps\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF','#AFAFAF'])\n",
    "    cmap_bold  = ListedColormap(['#FF0000', '#00FF00', '#0000FF','#AFAFAF'])\n",
    "    clf = KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "    clf.fit(X_mat, y_mat)\n",
    "# Plot the decision boundary by assigning a color in the color map\n",
    "    # to each mesh point.\n",
    "    \n",
    "    mesh_step_size = .01  # step size in the mesh\n",
    "    plot_symbol_size = 50\n",
    "    \n",
    "    x_min, x_max = X_mat[:, 0].min() - 1, X_mat[:, 0].max() + 1\n",
    "    y_min, y_max = X_mat[:, 1].min() - 1, X_mat[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, mesh_step_size),\n",
    "                         np.arange(y_min, y_max, mesh_step_size))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "# Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "# Plot training points\n",
    "    plt.scatter(X_mat[:, 0], X_mat[:, 1], s=plot_symbol_size, c=y, cmap=cmap_bold, edgecolor = 'black')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    patch0 = mpatches.Patch(color='#FF0000', label='apple')\n",
    "    patch1 = mpatches.Patch(color='#00FF00', label='mandarin')\n",
    "    patch2 = mpatches.Patch(color='#0000FF', label='orange')\n",
    "    patch3 = mpatches.Patch(color='#AFAFAF', label='lemon')\n",
    "    plt.legend(handles=[patch0, patch1, patch2, patch3])\n",
    "    plt.xlabel('height (cm)')\n",
    "    plt.ylabel('width (cm)')\n",
    "    plt.title(\"4-Class classification (k = %i, weights = '%s')\"\n",
    "           % (n_neighbors, weights))    \n",
    "    plt.show()\n",
    "\n",
    "plot_fruit_knn(X_train[['height', 'width']], y_train, 5, 'uniform')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The k-fold cross-validation procedure is a standard method for estimating the performance of a machine learning algorithm or configuration on a dataset.\n",
    "\n",
    "A single run of the k-fold cross-validation procedure may result in a noisy estimate of model performance. Different splits of the data may result in very different results.\n",
    "\n",
    "Repeated k-fold cross-validation provides a way to improve the estimated performance of a machine learning model. This involves simply repeating the cross-validation procedure multiple times and reporting the mean result across all folds from all runs. This mean result is expected to be a more accurate estimate of the true unknown underlying mean performance of the model on the dataset, as calculated using the standard error.\n",
    "\n",
    "#### Step 1. Create/Load Dataset\n",
    "Let us apply k-fold cross-validation procedure to a synthetic classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2. Set the parameter k\n",
    "\n",
    "Assume k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Define the model\n",
    "Consider the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4. Perform cross-validation and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "y_pred = cross_val_predict(model, X, y, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return the scores for each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Manual cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize cross-validation and define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make manual iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)\n",
    "for i in range(10):\n",
    "    result = next(cv.split(X), None)\n",
    "    x_train = X.iloc[result[0]]\n",
    "    x_test = X.iloc[result[1]]\n",
    "    y_train = y.iloc[result[0]]\n",
    "    y_test = y.iloc[result[1]]\n",
    "    model = model.fit(x_train, y_train.values.ravel())\n",
    "    #predictions = model.predict(x_test)\n",
    "    scores.append(model.score(x_test, y_test))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated Cross-Validation\n",
    "\n",
    "The estimate of model performance via k-fold cross-validation can be noisy.\n",
    "\n",
    "This means that each time the procedure is run, a different split of the dataset into k-folds can be implemented, and in turn, the distribution of performance scores can be different, resulting in a different mean estimate of model performance.\n",
    "\n",
    "One solution to reduce the noise in the estimated model performance is to increase the k-value. This will reduce the bias in the model’s estimated performance, although it will increase the variance: e.g. tie the result more to the specific dataset used in the evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `scikit-learn` Python machine learning library provides an implementation of repeated k-fold cross-validation via the `RepeatedKFold` class.\n",
    "\n",
    "The main parameters are the number of folds (n_splits), which is the “k” in k-fold cross-validation, and the number of repeats (n_repeats).\n",
    "\n",
    "A good default for k is k=10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "cvR = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X, y, scoring='accuracy', cv=cvR, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main results about cross-validation\n",
    "- The mean performance reported from a single run of k-fold cross-validation may be noisy.\n",
    "- Repeated k-fold cross-validation provides a way to reduce the error in the estimate of mean model performance.\n",
    "- How to evaluate machine learning models using repeated k-fold cross-validation in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced Data\n",
    "\n",
    "Imbalanced classes is a surprisingly common problem in machine learning (specifically in classification), occurring in datasets with a disproportionate ratio of observations in each class.\n",
    "\n",
    "**Standard accuracy no longer reliably measures performance, which makes model training much trickier.**\n",
    "\n",
    "Imbalanced classes appear in many domains, including:\n",
    "\n",
    "- Fraud detection\n",
    "- Spam filtering\n",
    "- Disease screening\n",
    "- SaaS subscription churn\n",
    "- Advertising click-throughs\n",
    "\n",
    "Thus, there is a need to explore **effective ways** to handle imbalanced classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use a synthetic dataset called *Balance Scale Data* (available at UCI Machine Learning Repository). The dataset contains information about whether a scale is balanced or not, based on weights and distances of the two arms.\n",
    "![Balance Scale Data](https://elitedatascience.com/wp-content/uploads/2017/06/balance-scale-data.png \"Balance Scale Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('balance-scale.data', \n",
    "                 names=['balance', 'var1', 'var2', 'var3', 'var4'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable has 3 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['balance'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume, we turn the data this into **a binary classification problem**. We're going to label each observation as 1 (positive class) if the scale is balanced or 0 (negative class) if the scale is not balanced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['balance'] = [1 if b=='B' else 0 for b in df.balance]\n",
    "df['balance'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, only about 8% of the observations were balanced. Therefore, **if we were to always predict 0, we'd achieve an accuracy of 92%.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Danger of Imbalanced Classes\n",
    "Let us apply the Logistic Regression algorithm to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.balance\n",
    "X = df.drop('balance', axis=1)\n",
    "\n",
    "LR = LogisticRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now make the prediction and evaluate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_0 = LR.predict(X)\n",
    "print(accuracy_score(pred_y_0, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our model has 92% overall accuracy, but is it because it's predicting only 1 class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this model is only predicting 0, which means it's completely ignoring the minority class in favor of the majority class.\n",
    "\n",
    "Next, we'll look at **some techniques for handling imbalanced classes**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Resampling Techniques](https://miro.medium.com/max/725/1*H6XodlitlGDl9YdbwaZLMw.png \"Resampling Techniques\")\n",
    "\n",
    "\n",
    "\n",
    "## 1. Up-sample Minority Class\n",
    "\n",
    "Up-sampling is the process of randomly duplicating observations from the minority class in order to reinforce its signal.\n",
    "\n",
    "\n",
    "There are several heuristics for doing so, but the most common way is to simply resample with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df.balance==0]\n",
    "df_minority = df[df.balance==1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=df_majority.shape[0],    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "df_upsampled.balance.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "y = df_upsampled.balance\n",
    "X = df_upsampled.drop('balance', axis=1)\n",
    "\n",
    "# Train model\n",
    "LR1 = LogisticRegression().fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_1 = LR1.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print(np.unique( pred_y_1 ))\n",
    "# [0 1]\n",
    " \n",
    "# How's our accuracy?\n",
    "print( accuracy_score(y, pred_y_1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now the model is no longer predicting just one class. While the accuracy also took a nosedive, it's now more meaningful as a performance metric.\n",
    "\n",
    "## 2. Down-sample Majority Class\n",
    "\n",
    "Down-sampling involves randomly removing observations from the majority class to prevent its signal from dominating the learning algorithm.\n",
    "\n",
    "The most common heuristic for doing so is resampling without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "df_majority = df[df.balance==0]\n",
    "df_minority = df[df.balance==1]\n",
    " \n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,    # sample without replacement\n",
    "                                 n_samples=49,     # to match minority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    " \n",
    "# Display new class counts\n",
    "df_downsampled.balance.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now apply the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate input features (X) and target variable (y)\n",
    "y = df_downsampled.balance\n",
    "X = df_downsampled.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "LR2 = LogisticRegression().fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_2 = LR2.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print(np.unique(pred_y_2))\n",
    " \n",
    "# How's our accuracy?\n",
    "print(accuracy_score(y, pred_y_2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model isn't predicting just one class, and the accuracy seems higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Change Your Performance Metric\n",
    "\n",
    "For a general-purpose metric for classification, we recommend Area Under ROC Curve (AUROC). Intuitively, AUROC represents the likelihood of your model distinguishing observations from two classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class probabilities\n",
    "prob_y_2 = LR2.predict_proba(X)\n",
    "\n",
    "# Keep only the positive class\n",
    "prob_y_2 = [p[1] for p in prob_y_2]\n",
    "\n",
    "prob_y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_score(y, prob_y_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare to the original model trained on the imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_y_0 = LR.predict_proba(X)\n",
    "prob_y_0 = [p[0] for p in prob_y_0] # AUROC should be >= 0.5. If you got <0.5, you should change p[0] to p[1]\n",
    " \n",
    "print(roc_auc_score(y, prob_y_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can observe that AUROC is higher for LR2 (Down-sampling) compared to the initial model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use Penalize Algorithms (Cost-Sensitive Training)\n",
    "\n",
    "The next tactic is to use penalized learning algorithms that increase the cost of classification mistakes on the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "y = df.balance\n",
    "X = df.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "model3 = SVC(kernel='linear', \n",
    "            class_weight='balanced', # penalize proportianally to the size of the classes\n",
    "            probability=True)\n",
    " \n",
    "model3.fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_3 = model3.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print(\"Predicted classes\", np.unique( pred_y_3 ))\n",
    "\n",
    "# How's our accuracy?\n",
    "print(\"Accuracy\", accuracy_score(y, pred_y_3))\n",
    "\n",
    "# What about AUROC?\n",
    "prob_y_3 = model3.predict_proba(X)\n",
    "prob_y_3 = [p[0] for p in prob_y_3]\n",
    "print(\"AUROC is\",roc_auc_score(y, prob_y_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use Tree-Based Algorithms\n",
    "The final tactic we'll consider is using tree-based algorithms. Decision trees often perform well on imbalanced datasets because their hierarchical structure allows them to learn signals from both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.balance\n",
    "X = df.drop('balance', axis=1)\n",
    " \n",
    "# Train model\n",
    "model4 = RandomForestClassifier()\n",
    "model4.fit(X, y)\n",
    " \n",
    "# Predict on training set\n",
    "pred_y_4 = model4.predict(X)\n",
    " \n",
    "# Is our model still predicting just one class?\n",
    "print(\"Predicted classes\", np.unique(pred_y_4 ))\n",
    " \n",
    "# How's our accuracy?\n",
    "print(\"Accuracy\", accuracy_score(y, pred_y_4))\n",
    "# 0.9744\n",
    " \n",
    "# What about AUROC?\n",
    "prob_y_4 = model4.predict_proba(X)\n",
    "prob_y_4 = [p[1] for p in prob_y_4]\n",
    "print(\"AUROC is\", roc_auc_score(y, prob_y_4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, tree ensembles have become very popular because they perform extremely well on many real-world problems. We certainly recommend them wholeheartedly.\n",
    "\n",
    "**However:**\n",
    "\n",
    "While these results are encouraging, the model could be **overfit**, so you should still evaluate your model on an unseen test set before making the final decision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "Consider the BykeBuyer dataset (BykeBuyer.xls, available at LMS system). Divide the dataset into the test and training data. Predict byke buyers using various classification models. Evaluate the performance of the models (classification scores + repeated k-cross-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
